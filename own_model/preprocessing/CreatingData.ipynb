{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "051e96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from functools import reduce\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c3b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data(series):\n",
    "    first = series[0]\n",
    "    series = list(series[1:])\n",
    "    series.append(first)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb98f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1000.csv\n",
      "df_10000.csv\n",
      "df_100000.csv\n",
      "df_101000.csv\n",
      "df_102000.csv\n",
      "df_103000.csv\n",
      "df_104000.csv\n",
      "df_105000.csv\n",
      "df_106000.csv\n",
      "df_107000.csv\n",
      "df_108000.csv\n",
      "df_109000.csv\n",
      "df_11000.csv\n",
      "df_110000.csv\n",
      "df_111000.csv\n",
      "df_112000.csv\n",
      "df_113000.csv\n",
      "df_114000.csv\n",
      "df_115000.csv\n",
      "df_116000.csv\n",
      "df_117000.csv\n",
      "df_118000.csv\n",
      "df_119000.csv\n",
      "df_12000.csv\n",
      "df_120000.csv\n",
      "df_121000.csv\n",
      "df_122000.csv\n",
      "df_123000.csv\n",
      "df_124000.csv\n",
      "df_125000.csv\n",
      "df_126000.csv\n",
      "df_127000.csv\n",
      "df_128000.csv\n",
      "df_129000.csv\n",
      "df_13000.csv\n",
      "df_130000.csv\n",
      "df_131000.csv\n",
      "df_132000.csv\n",
      "df_133000.csv\n",
      "df_134000.csv\n",
      "df_135000.csv\n",
      "df_136000.csv\n",
      "df_137000.csv\n",
      "df_138000.csv\n",
      "df_139000.csv\n",
      "df_14000.csv\n",
      "df_140000.csv\n",
      "df_141000.csv\n",
      "df_142000.csv\n",
      "df_143000.csv\n",
      "df_15000.csv\n",
      "df_16000.csv\n",
      "df_17000.csv\n",
      "df_18000.csv\n",
      "df_19000.csv\n",
      "df_2000.csv\n",
      "df_20000.csv\n",
      "df_21000.csv\n",
      "df_22000.csv\n",
      "df_23000.csv\n",
      "df_24000.csv\n",
      "df_25000.csv\n",
      "df_26000.csv\n",
      "df_27000.csv\n",
      "df_28000.csv\n",
      "df_29000.csv\n",
      "df_3000.csv\n",
      "df_30000.csv\n",
      "df_31000.csv\n",
      "df_32000.csv\n",
      "df_33000.csv\n",
      "df_34000.csv\n",
      "df_35000.csv\n",
      "df_36000.csv\n",
      "df_37000.csv\n",
      "df_38000.csv\n",
      "df_39000.csv\n",
      "df_4000.csv\n",
      "df_40000.csv\n",
      "df_41000.csv\n",
      "df_42000.csv\n",
      "df_43000.csv\n",
      "df_44000.csv\n",
      "df_45000.csv\n",
      "df_46000.csv\n",
      "df_47000.csv\n",
      "df_48000.csv\n",
      "df_49000.csv\n",
      "df_5000.csv\n",
      "df_50000.csv\n",
      "df_51000.csv\n",
      "df_52000.csv\n",
      "df_53000.csv\n",
      "df_54000.csv\n",
      "df_55000.csv\n",
      "df_56000.csv\n",
      "df_57000.csv\n",
      "df_58000.csv\n",
      "df_59000.csv\n",
      "df_6000.csv\n",
      "df_60000.csv\n",
      "df_61000.csv\n",
      "df_62000.csv\n",
      "df_63000.csv\n",
      "df_64000.csv\n",
      "df_65000.csv\n",
      "df_66000.csv\n",
      "df_67000.csv\n",
      "df_68000.csv\n",
      "df_69000.csv\n",
      "df_7000.csv\n",
      "df_70000.csv\n",
      "df_71000.csv\n",
      "df_72000.csv\n",
      "df_73000.csv\n",
      "df_74000.csv\n",
      "df_75000.csv\n",
      "df_76000.csv\n",
      "df_77000.csv\n",
      "df_78000.csv\n",
      "df_79000.csv\n",
      "df_8000.csv\n",
      "df_80000.csv\n",
      "df_81000.csv\n",
      "df_82000.csv\n",
      "df_83000.csv\n",
      "df_84000.csv\n",
      "df_85000.csv\n",
      "df_86000.csv\n",
      "df_87000.csv\n",
      "df_88000.csv\n",
      "df_89000.csv\n",
      "df_9000.csv\n",
      "df_90000.csv\n",
      "df_91000.csv\n",
      "df_92000.csv\n",
      "df_93000.csv\n",
      "df_94000.csv\n",
      "df_95000.csv\n",
      "df_96000.csv\n",
      "df_97000.csv\n",
      "df_98000.csv\n",
      "df_99000.csv\n"
     ]
    }
   ],
   "source": [
    "directory = 'data100codes'\n",
    "destination = 'data100sentences'\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    print(file)\n",
    "    data = pd.read_csv(os.path.join(directory,file))\n",
    "    data['wrong'] = move_data(data['passage'])\n",
    "    data.to_csv(os.path.join(destination, file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80b343ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data100codes'\n",
    "destination = 'data100words'\n",
    "\n",
    "window_len = 3\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    with open(os.path.join(destination, file), 'w', encoding='utf-8') as out_file:\n",
    "        data = pd.read_csv(os.path.join(directory,file))\n",
    "        out_file.write(\"word1,word2\\n\")\n",
    "\n",
    "        for row in range(len(data)):\n",
    "            for col in [\"question\", \"passage\"]:\n",
    "                curr_phrase = data.iloc[row][col].split()\n",
    "                for index, word in enumerate(curr_phrase):\n",
    "                    for offset in range(-window_len, window_len + 1):\n",
    "                        target = index + offset\n",
    "                        if offset != 0 and target < len(curr_phrase) and target >= 0:\n",
    "                            out_file.write(f\"{word},{curr_phrase[target]}\\n\")\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0427c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data100words'\n",
    "dataframes = map(lambda x: pd.read_csv(os.path.join(directory, x)), os.listdir(directory))\n",
    "data = reduce(lambda x,y: pd.concat([x,y]).reset_index(drop=True), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a43b7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = data['word1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d571260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24,    2,    0, ..., 9392, 9393, 9394], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c717f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca8184d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = 'wrongwords100'\n",
    "\n",
    "for word in words:\n",
    "    current_data = data[data['word1'] == word].copy()\n",
    "    avoid = current_data['word2'].unique()\n",
    "    \n",
    "    randoms = np.zeros(len(current_data), dtype = np.int64)\n",
    "    for index in range(len(current_data)):\n",
    "        random_number = randint(0, len(words)-1)\n",
    "        while random_number in avoid or random_number == word:\n",
    "            random_number = randint(0, len(words)-1)\n",
    "        randoms[index] = random_number\n",
    "    \n",
    "    current_data['wrong'] = randoms\n",
    "    current_data.to_csv(os.path.join(destination, f'word{word}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
